{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS-109A Introduction to Data Science\n",
    "\n",
    "\n",
    "## Lab 6: Logistic Regression \n",
    "\n",
    "**Harvard University**<br>\n",
    "**Fall 2019**<br>\n",
    "**Instructors:** Pavlos Protopapas, Kevin Rader, Chris Tanner<br>\n",
    "**Lab Instructors:** Chris Tanner and Eleni Kaxiras.  <br>\n",
    "**Contributors:** Chris Tanner\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Learning Goals (EDIT)\n",
    "In this lab, we'll explore different models used to predict which of several labels applies to a new datapoint based on labels observed in the training data.\n",
    "\n",
    "By the end of this lab, you should:\n",
    "- Be familiar with the `sklearn` implementations of\n",
    " - Linear Regression\n",
    " - Logistic Regression\n",
    "- Be able to make an informed choice of model based on the data at hand\n",
    "- (Bonus) Structure your sklearn code into Pipelines to make building, fitting, and tracking your models easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTS GALORE\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1:  The AirBnB NYC 2019 Dataset + EDA\n",
    "The dataset contains information about AirBnB hosts in NYC from 2019. There are 49k unique hosts and 16 features for each:\n",
    "\n",
    "- **id:** listing ID\n",
    "- **name:** name of the listing\n",
    "- **host_id:** host ID\n",
    "- **host_name:** name of the host\n",
    "- **neighbourhood_group:** NYC borough\n",
    "- **neighbourhood:** neighborhood\n",
    "- **latitude:** latitude coordinates\n",
    "- **longitude:** longitude coordinates\n",
    "- **room_type:** listing space type (e.g., private room, entire home)\n",
    "- **price:** price in dollars per night\n",
    "- **minimum_nights:** number of min. nights required for booking\n",
    "- **number_of_reviews:** number of reviews\n",
    "- **last_review:** date of the last review\n",
    "- **reviews_per_month:** number of reviews per month\n",
    "- **calculated_host_listings_count:** number of listings the host has\n",
    "- **availability_365:** number of days the listing is available for booking\n",
    "\n",
    "Our goal is to predict the price of unseen housing units as being 'affordable' or 'unaffordable', by using their features. We will assume that this task is for a particular client who has a specific budget and would like to simplify the problem by classifying any unit that costs \\< \\\\$150 per night as 'affordable' and any unit that costs \\\\$150 or great as 'unaffordable'.\n",
    "\n",
    "For this task, we will exercise our normal data science pipeline -- from EDA to modelling and visualization. In particular, we will show the performance of 3 classifiers:\n",
    "\n",
    "- Maximum Likelihood Estimate (MLE)\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "\n",
    "Let's get started! And awaaaaay we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-in and checking\n",
    "We do the usual read-in and verification of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id    host_name neighbourhood_group neighbourhood  latitude  longitude        room_type  price  minimum_nights  number_of_reviews last_review  reviews_per_month  calculated_host_listings_count  availability_365\n",
       "0  2539                Clean & quiet apt home by the park     2787         John            Brooklyn    Kensington  40.64749  -73.97237     Private room    149               1                  9  2018-10-19               0.21                               6               365\n",
       "1  2595                             Skylit Midtown Castle     2845     Jennifer           Manhattan       Midtown  40.75362  -73.98377  Entire home/apt    225               1                 45  2019-05-21               0.38                               2               355\n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632    Elisabeth           Manhattan        Harlem  40.80902  -73.94190     Private room    150               3                  0         NaN                NaN                               1               365\n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976  Entire home/apt     89               1                270  2019-07-05               4.64                               1               194\n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192        Laura           Manhattan   East Harlem  40.79851  -73.94399  Entire home/apt     80              10                  9  2018-11-19               0.10                               1                 0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/nyc_airbnb.csv\") #, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the training/dev/testing data\n",
    "As usual, we split the data before we begin our analysis. It would be unfair to cheat by looking at the testing data. Let's divide the data into 60% training, 20% development (aka validation), 20% testing. However, before we split the data, let's make the simple transformation and converting the prices into a categories of being _affordable_ or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48895, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>affordable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id    host_name neighbourhood_group neighbourhood  latitude  longitude        room_type  price  minimum_nights  number_of_reviews last_review  reviews_per_month  calculated_host_listings_count  availability_365  affordable\n",
       "0  2539                Clean & quiet apt home by the park     2787         John            Brooklyn    Kensington  40.64749  -73.97237     Private room    149               1                  9  2018-10-19               0.21                               6               365           1\n",
       "1  2595                             Skylit Midtown Castle     2845     Jennifer           Manhattan       Midtown  40.75362  -73.98377  Entire home/apt    225               1                 45  2019-05-21               0.38                               2               355           0\n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632    Elisabeth           Manhattan        Harlem  40.80902  -73.94190     Private room    150               3                  0         NaN                NaN                               1               365           0\n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976  Entire home/apt     89               1                270  2019-07-05               4.64                               1               194           1\n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192        Laura           Manhattan   East Harlem  40.79851  -73.94399  Entire home/apt     80              10                  9  2018-11-19               0.10                               1                 0           1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['affordable'] = np.where(df['price'] < 150, 1, 0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The `affordable` column now has a value of 1 whenever the price is < 150, and 0 otherwise.\n",
    "\n",
    "Also, the feature named `neighbourhood_group` can be easily confused with `neighbourhood`, so let's go ahead and rename it to `borough`, as that is more distinct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>borough</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>affordable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id    host_name    borough neighbourhood  latitude  longitude        room_type  price  minimum_nights  number_of_reviews last_review  reviews_per_month  calculated_host_listings_count  availability_365  affordable\n",
       "0  2539                Clean & quiet apt home by the park     2787         John   Brooklyn    Kensington  40.64749  -73.97237     Private room    149               1                  9  2018-10-19               0.21                               6               365           1\n",
       "1  2595                             Skylit Midtown Castle     2845     Jennifer  Manhattan       Midtown  40.75362  -73.98377  Entire home/apt    225               1                 45  2019-05-21               0.38                               2               355           0\n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632    Elisabeth  Manhattan        Harlem  40.80902  -73.94190     Private room    150               3                  0         NaN                NaN                               1               365           0\n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869  LisaRoxanne   Brooklyn  Clinton Hill  40.68514  -73.95976  Entire home/apt     89               1                270  2019-07-05               4.64                               1               194           1\n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192        Laura  Manhattan   East Harlem  40.79851  -73.94399  Entire home/apt     80              10                  9  2018-11-19               0.10                               1                 0           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={\"neighbourhood_group\": \"borough\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without looking at the full data yet, let's just ensure our prices are within valid ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    48895.000000\n",
       "mean       152.720687\n",
       "std        240.154170\n",
       "min          0.000000\n",
       "25%         69.000000\n",
       "50%        106.000000\n",
       "75%        175.000000\n",
       "max      10000.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh-oh. We see that `price` has a minimum value of \\\\$0. I highly doubt any unit in NYC is free. These data instances are garbage, so let's go ahead and remove any instance that has a price of \\\\$0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original training size: (48895, 17)\n",
      "new training size: (48884, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"original training size:\", df.shape)\n",
    "df = df.loc[df['price'] != 0]\n",
    "print(\"new training size:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16985, 31899], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(df['affordable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31899\n",
       "0    16985\n",
       "Name: affordable, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['affordable'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split the data while ensuring that our test set has a fair distribution of affordable units, then further split our training set so as to create the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 29330 => 0.5999918173635546\n",
      "dev: 9777  => 0.20000409131822272\n",
      "test: 9777 => 0.20000409131822272\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['affordable'])\n",
    "df_train, df_dev = train_test_split(df_train, test_size=0.25, random_state=99) #stratify=df_train['affordable'])\n",
    "\n",
    "# ensure our dataset splits are of the % sizes we want\n",
    "total_size = len(df_train) + len(df_dev) + len(df_test)\n",
    "print(\"train:\", len(df_train), \"=>\", len(df_train) / total_size)\n",
    "print(\"dev:\", len(df_dev), \" =>\", len(df_dev) / total_size)\n",
    "print(\"test:\", len(df_test), \"=>\", len(df_test) / total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the target value (i.e., __affordable__) from our current dataframes and create it as separate prediction dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "x_train = df_train.drop(['price', 'affordable'], axis=1)\n",
    "y_train = pd.DataFrame(data=df_train['affordable'], columns=[\"affordable\"])\n",
    "\n",
    "# dev\n",
    "x_dev = df_dev.drop(['price', 'affordable'], axis=1)\n",
    "y_dev = pd.DataFrame(data=df_dev['affordable'], columns=[\"affordable\"])\n",
    "\n",
    "# test\n",
    "x_test = df_test.drop(['price', 'affordable'], axis=1)\n",
    "y_test = pd.DataFrame(data=df_test['affordable'], columns=[\"affordable\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now onwards, we will do EDA and cleaning based on the training set, `x_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 0\n",
      "name : 12\n",
      "host_id : 0\n",
      "host_name : 12\n",
      "borough : 0\n",
      "neighbourhood : 0\n",
      "latitude : 0\n",
      "longitude : 0\n",
      "room_type : 0\n",
      "minimum_nights : 0\n",
      "number_of_reviews : 0\n",
      "last_review : 6065\n",
      "reviews_per_month : 6065\n",
      "calculated_host_listings_count : 0\n",
      "availability_365 : 0\n"
     ]
    }
   ],
   "source": [
    "for col in x_train.columns:\n",
    "    print(col, \":\", np.sum([x_train[col].isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                   0\n",
       "name                                12\n",
       "host_id                              0\n",
       "host_name                           12\n",
       "borough                              0\n",
       "neighbourhood                        0\n",
       "latitude                             0\n",
       "longitude                            0\n",
       "room_type                            0\n",
       "minimum_nights                       0\n",
       "number_of_reviews                    0\n",
       "last_review                       6065\n",
       "reviews_per_month                 6065\n",
       "calculated_host_listings_count       0\n",
       "availability_365                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Oh dear. It appears ~6k of the rows have missing values concerning the reviews. It seems impossible to impute the `last_review` feature with reasonable values, as this is very specific to each unit. At best, we could guess the date based on the `reviews_per_month`, but that feature is missing for the same rows. Further, it might be difficult to replace `reviews_per_month` with reasonable values -- sure, we could fill in values to be the median value, but that seems wrong to generalize so heavily, especially for over 20% of our data. Consequently, let's just ignore these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['last_review', 'reviews_per_month'], axis=1)\n",
    "x_dev = x_dev.drop(['last_review', 'reviews_per_month'], axis=1)\n",
    "x_test = x_test.drop(['last_review', 'reviews_per_month'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the summary statistics of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.933000e+04</td>\n",
       "      <td>2.933000e+04</td>\n",
       "      <td>29330.000000</td>\n",
       "      <td>29330.000000</td>\n",
       "      <td>29330.000000</td>\n",
       "      <td>29330.000000</td>\n",
       "      <td>29330.000000</td>\n",
       "      <td>29330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.899091e+07</td>\n",
       "      <td>6.746725e+07</td>\n",
       "      <td>40.729049</td>\n",
       "      <td>-73.952129</td>\n",
       "      <td>6.891647</td>\n",
       "      <td>23.490829</td>\n",
       "      <td>7.111081</td>\n",
       "      <td>113.047017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.102972e+07</td>\n",
       "      <td>7.863754e+07</td>\n",
       "      <td>0.054446</td>\n",
       "      <td>0.046320</td>\n",
       "      <td>19.236816</td>\n",
       "      <td>45.324235</td>\n",
       "      <td>32.904893</td>\n",
       "      <td>131.845296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.539000e+03</td>\n",
       "      <td>2.438000e+03</td>\n",
       "      <td>40.499790</td>\n",
       "      <td>-74.242850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.380684e+06</td>\n",
       "      <td>7.794212e+06</td>\n",
       "      <td>40.690423</td>\n",
       "      <td>-73.983130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.960499e+07</td>\n",
       "      <td>3.049924e+07</td>\n",
       "      <td>40.723090</td>\n",
       "      <td>-73.955630</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.921518e+07</td>\n",
       "      <td>1.074344e+08</td>\n",
       "      <td>40.763067</td>\n",
       "      <td>-73.936100</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.648561e+07</td>\n",
       "      <td>2.743213e+08</td>\n",
       "      <td>40.913060</td>\n",
       "      <td>-73.712990</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>365.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       host_id      latitude     longitude  minimum_nights  number_of_reviews  calculated_host_listings_count  availability_365\n",
       "count  2.933000e+04  2.933000e+04  29330.000000  29330.000000    29330.000000       29330.000000                    29330.000000      29330.000000\n",
       "mean   1.899091e+07  6.746725e+07     40.729049    -73.952129        6.891647          23.490829                        7.111081        113.047017\n",
       "std    1.102972e+07  7.863754e+07      0.054446      0.046320       19.236816          45.324235                       32.904893        131.845296\n",
       "min    2.539000e+03  2.438000e+03     40.499790    -74.242850        1.000000           0.000000                        1.000000          0.000000\n",
       "25%    9.380684e+06  7.794212e+06     40.690423    -73.983130        1.000000           1.000000                        1.000000          0.000000\n",
       "50%    1.960499e+07  3.049924e+07     40.723090    -73.955630        3.000000           5.000000                        1.000000         44.000000\n",
       "75%    2.921518e+07  1.074344e+08     40.763067    -73.936100        5.000000          24.000000                        2.000000        228.000000\n",
       "max    3.648561e+07  2.743213e+08     40.913060    -73.712990     1000.000000         629.000000                      327.000000        365.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we see that the `minimum_nights` feature has a maximum value of 1,250. That's almost 3.5 years, which is probably longer than the duration that most people rent an apartment. This seems anomalous and wrong. Let's discard it and other units that are outrageous. Well, what constitutes 'outrageous'? We see that the standard deviation for `minimum_nights` is 21.24. If we assume our distribution of values are normally distributed, then only using values that are within 2 standard deviations of the mean would yield us with ~95% of the original data. However, we have no reason to believe our data is actually normally distributed, especially since our mean is 7. To have a better idea of our actual values, let's plot it as a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(x_train['minimum_nights'], 25, log=True)\n",
    "plt.xlabel('minimum_nights')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATtUlEQVR4nO3df6zdd33f8ecr9vKjoaTQuAj8Yw5ylNVFFdDbUFI2sYI6pxDSMgZxqUqmLIZOqQao3cKYhCptEp3QBBlpwQ2paZclZCnN4tQlbJQQdckgTsbAIaQ1SakvYcSUNURla2r83h/n62/OzL2+59r343O/5z4f0pXP+Zzv93ven2Mnr/v9fr7n80lVIUkSwBnTLkCStHoYCpKknqEgSeoZCpKknqEgSeqtn3YBp+L888+vrVu3TrsMSRqUBx544JtVtWGh1wYdClu3bmX//v3TLkOSBiXJVxd7zctHkqSeoSBJ6g0yFJJclmT3k08+Oe1SJGmmDDIUqmpvVe0677zzpl2KJM2UQYaCJKkNQ0GS1DMUJEk9Q0GS1BtkKKzE3UcbN28hycQ/GzdvWcEeSNLqlCEvsjM3N1cn+43mJLzpw/dOvP3H3noJQ/6sJOmYJA9U1dxCrw3yTEGS1IahIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqDTIUnCVVktoYZCg4S6oktTHIUJAktWEoSJJ6hoIkqWcoSJJ6hoIkqWcoSJJ6hoIkqbeqQiHJuUkeSPLaadciSWtR01BIcmOSJ5IcOK59R5JHkhxMcu3YS/8CuLVlTZKkxbU+U9gD7BhvSLIOuB64FNgO7EyyPcmrgS8B32hckyRpEetbHryq7kmy9bjmi4GDVfUoQJJbgMuBZwHnMgqK/5NkX1UdbVmfJOn/1zQUFrERODT2fB54WVVdA5DkSuCbiwVCkl3ALoAtW7a0rVSS1phpDDRngbbqH1Ttqao7F9u5qnZX1VxVzW3YsKFJgZK0Vk0jFOaBzWPPNwGPL+cATp0tSW1MIxTuBy5MckGSM4ErgDuWcwCnzpakNlrfknozcB9wUZL5JFdV1RHgGuAu4GHg1qp6aJnH9UxBkhpofffRzkXa9wH7TuG4e4G9c3NzV5/sMSRJ32tVfaNZkjRdgwwFLx9JUhuDDAUHmiWpjUGGgiSpjUGGgpePJKmNQYaCl48kqY1BhoIkqY1BhoKXjySpjUGGgpePJKmNQYaCJKkNQ0GS1BtkKDimIEltDDIUHFOQpDYGGQqSpDYMBUlSz1CQJPUMBUlSb5Ch4N1HktTGIEPBu48kqY1BhoIkqQ1DQZLUMxQkST1DQZLUMxQkST1DQZLUG2Qo+D0FSWpjkKHg9xQkqY1BhoIkqQ1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUWzWhkOSHk3woyW1Jfmna9UjSWtQ0FJLcmOSJJAeOa9+R5JEkB5NcC1BVD1fV24A3AnMt65IkLaz1mcIeYMd4Q5J1wPXApcB2YGeS7d1rrwP+GPhU47okSQtoGgpVdQ/wreOaLwYOVtWjVfU0cAtwebf9HVV1CfDmxY6ZZFeS/Un2Hz58uFXpkrQmrZ/Ce24EDo09nwdeluSVwOuBs4B9i+1cVbuB3QBzc3PVrEpJWoOmEQpZoK2q6m7g7okOkFwGXLZt27YVLEuSNI27j+aBzWPPNwGPL+cATp0tSW1MIxTuBy5MckGSM4ErgDuWcwAX2ZGkNlrfknozcB9wUZL5JFdV1RHgGuAu4GHg1qp6aDnH9UxBktpoOqZQVTsXad/HCQaTJUnTsWq+0bwcXj6SpDYGGQpePpKkNgYZCpKkNgYZCl4+kqQ2BhkKXj6SpDYGGQqSpDYGGQpePpKkNgYZCl4+kqQ2BhkKkqQ2DAVJUs9QkCT1BhkKDjRLUhuDDAUHmiWpjUGGgiSpDUNBktSbKBSS/OQkbZKkYZv0TOHfT9h2WjjQLEltnHDltSQvBy4BNiR559hLzwbWtSzsRKpqL7B3bm7u6mnVIEmzaKnlOM8EntVt9/1j7d8G3tCqKEnSdJwwFKrqM8Bnkuypqq+eppokSVOy1JnCMWcl2Q1sHd+nqn6qRVGSpOmYNBT+E/Ah4Abgu+3KkSRN06ShcKSqfrNpJZKkqZv0ltS9Sf5pkucnee6xn6aVSZJOu0nPFN7S/fmrY20FvHBly5lMksuAy7Zt2zaNt5ekmTXRmUJVXbDAz1QCoavHCfEkqYGJzhSS/OJC7VX1OytbjiRpmia9fPTjY4/PBl4FPAgYCpI0QyYKhar65fHnSc4DfrdJRZKkqTnZqbO/A1y4koVIkqZv0jGFvYzuNoLRRHg/DNzaqihJ0nRMOqbwvrHHR4CvVtV8g3okSVM06S2pnwG+zGim1OcAT7csSpI0HZOuvPZG4HPAPwLeCHw2iVNnS9KMmfTy0buBH6+qJwCSbAD+K3DbShaT5GeB1wA/BFxfVZ9cyeOfkjPWk2RZu7xg02a+dujPGxUkSStv0lA441ggdP6Cyc8ybgReCzxRVS8aa98BfIDRwPUNVfXeqroduD3JcxiNY6yeUDh6hDd9+N5l7fKxt17SqBhJamPSW1I/keSuJFcmuRL4A2DfhPvuAXaMNyRZB1wPXApsB3Ym2T62yb/qXpcknUZLrdG8DXheVf1qktcDrwAC3AfcNMkbVNU9SbYe13wxcLCqHu3e5xbg8iQPA+8F/rCqHlykpl3ALoAtW7ZMUoIkaUJLnSm8H3gKoKo+XlXvrKp3MDpLeP8pvO9G4NDY8/mu7ZeBVwNvSPK2hXasqt1VNVdVcxs2bDiFEiRJx1tqTGFrVX3h+Maq2r/Ab//LsdCIbVXVdcB1S+7s1NmS1MRSZwpnn+C1c07hfeeBzWPPNwGPT7rzYKbO7u5YmvRn42Yvh0marqXOFO5PcnVV/dZ4Y5KrgAdO4X3vBy5McgHwNeAK4OdP4Xir0zLvWPJuJUnTtlQovB34/SRv5pkQmAPOBH5ukjdIcjPwSuD8JPPAe6rqI0muAe5idEvqjVX10KRFe/lIkto4YShU1TeAS5L8feDYdwz+oKr+aNI3qKqdi7TvY/LbWo/fdy+wd25u7uqT2V+StLBJ11P4NPDpxrVMzDMFSWrjZNdTmKrBDDRL0sAMMhQkSW0MMhSSXJZk95NPPjntUiRppgwyFLx8JEltDDIUJEltGAqSpN4gQ8ExBUlqY5Ch4JiCJLUxyFCQJLVhKEiSeoMMBccUJKmNQYaCYwqS1MYgQ0GS1IahIEnqGQoDtnHzFpf7lLSiJlpPQavT4/OHXO5T0ooa5JmCdx9JUhuDDAXvPpKkNgYZCpKkNgwFSVLPUJAk9QwFSVLPUJAk9QYZCt6SKkltDDIUvCVVktoYZCho7XJqD6ktp7nQoDi1h9SWZwqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqrZpQSPLCJB9Jctu0a5GktappKCS5MckTSQ4c174jySNJDia5FqCqHq2qq1rWI0k6sdZnCnuAHeMNSdYB1wOXAtuBnUm2N65DkjSBpqFQVfcA3zqu+WLgYHdm8DRwC3B5yzokSZOZxpjCRuDQ2PN5YGOSH0zyIeAlSd612M5JdiXZn2T/4cOHW9cqSWvKNOY+ygJtVVV/AbxtqZ2rajewG2Bubq5WuDZJWtOmcaYwD2wee74JeHw5B3A9BUlqYxqhcD9wYZILkpwJXAHcsZwDuJ6CJLXR+pbUm4H7gIuSzCe5qqqOANcAdwEPA7dW1UPLPK5nCpLUQNMxharauUj7PmDfKRx3L7B3bm7u6pM9hiTpe62abzRLkqZvkKHg5SNJamOQoeBAsyS1MchQkCS1MchQ8PKRJLUxyFDw8pEktTHIUJAktTHIUJjZy0dnrCfJxD+tj79x85aV76OkVW0aE+Kdspn98trRI7zpw/dOvPnH3nrJ6jq+pMEb5JmCJKkNQ0GS1BtkKMzsmMLAbdy8ZVljFklYf+bZbcdRGjuZPjtWo9XMMQWtmMfnDy1rzAJG4xZDHuc42T5Lq9UgzxQkSW0YCpKknqEgSeoZCpKk3iBDwbuPJKmNQYaCE+JJUhuDDAVJUhuGgiSpZyhIknqGgiSpZyhIknqGgiSpN8hQ8HsKkmbJappt11lSJWnKVtNsu4M8U5AktWEoSJJ6hoIkqWcoSJJ6hoIkqWcoSJJ6hoIkqWcoSJJ6q+bLa0nOBX4DeBq4u6pumnJJkrTmND1TSHJjkieSHDiufUeSR5IcTHJt1/x64Laquhp4Xcu6JEkLa335aA+wY7whyTrgeuBSYDuwM8l2YBNwqNvsu43rkiQtoGkoVNU9wLeOa74YOFhVj1bV08AtwOXAPKNgOGFdSXYl2Z9k/+HDh1uUrWPOWL+sCbpmwXInJpNmzTTGFDbyzBkBjMLgZcB1wAeTvAbYu9jOVbUb2A0wNzdXDevU0SPLmqSr1QRdp9NyJyabhT5L46YRCgv9elVV9VfAP57oAMllwGXbtm1b0cIkaa2bxi2p88DmseebgMeXc4Cq2ltVu84777wVLUyS1rpphML9wIVJLkhyJnAFcMdyDuAiO5LURutbUm8G7gMuSjKf5KqqOgJcA9wFPAzcWlUPLee4nilIUhtNxxSqauci7fuAfS3fW5K0fIOc5sLLR5LUxiBDwctHktTGIENBktRGqob3/a9j31MA3gT86Uke5nzgmytW1DDY57XBPq8Np9Lnv11VGxZ6YZChsBKS7K+quWnXcTrZ57XBPq8Nrfrs5SNJUs9QkCT11nIo7J52AVNgn9cG+7w2NOnzmh1TkCR9r7V8piBJOo6hIEnqrblQWGR96MFLsjnJp5M8nOShJP+sa39ukv+S5E+7P58zts+7us/hkST/YHrVn5ok65L8jyR3ds9nus9JfiDJbUm+3P19v3wN9Pkd3b/rA0luTnL2rPV5oTXtT6aPSX4syRe7167LcpcIrKo18wOsA74CvBA4E/ifwPZp17VCfXs+8NLu8fcDf8JoDex/C1zbtV8L/Hr3eHvX/7OAC7rPZd20+3GSfX8n8B+BO7vnM91n4KPAP+kenwn8wCz3mdFqjY8B53TPbwWunLU+A38PeClwYKxt2X0EPge8nNGCZn8IXLqcOtbamcJi60MPXlV9vaoe7B4/xWha8o2M+vfRbrOPAj/bPb4cuKWq/rqqHgMOMvp8BiXJJuA1wA1jzTPb5yTPZvQ/j48AVNXTVfWXzHCfO+uBc5KsB76P0cJcM9XnWnhN+2X1McnzgWdX1X01SojfGdtnImstFBZaH3rjlGppJslW4CXAZ4HnVdXXYRQcwA91m83KZ/F+4J8DR8faZrnPLwQOA7/dXTK7Icm5zHCfq+prwPuAPwe+DjxZVZ9khvs8Zrl93Ng9Pr59YmstFBZcH/q0V9FQkmcBvwe8vaq+faJNF2gb1GeR5LXAE1X1wKS7LNA2qD4z+o35pcBvVtVLgL9idFlhMYPvc3cd/XJGl0leAJyb5BdOtMsCbYPq8wQW6+Mp932thcIprw+9miX5W4wC4aaq+njX/I3ulJLuzye69ln4LH4SeF2SP2N0KfCnkvwHZrvP88B8VX22e34bo5CY5T6/Gnisqg5X1d8AHwcuYbb7fMxy+zjfPT6+fWJrLRROeX3o1aq7w+AjwMNV9e/GXroDeEv3+C3Afx5rvyLJWUkuAC5kNEA1GFX1rqraVFVbGf1d/lFV/QKz3ef/BRxKclHX9CrgS8xwnxldNvqJJN/X/Tt/FaMxs1nu8zHL6mN3iempJD/RfVa/OLbPZKY94j6FEf6fYXRnzleAd0+7nhXs1ysYnSZ+Afh89/MzwA8Cn2I0xfingOeO7fPu7nN4hGXeobDafoBX8szdRzPdZ+DFwP7u7/p24DlroM+/BnwZOAD8LqO7bmaqz8DNjMZM/obRb/xXnUwfgbnuc/oK8EG6mSsm/XGaC0lSb61dPpIknYChIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqaWUlet9T06ElekOS201XTciWZS3LdEttsHZ9u+bjXrkzygjbVaRb5PQVp4LoJEO+sqhct8NrdwK9U1f7TXZeGyTMFDVL32/GXu1lCDyS5Kcmrk/y3bkGSi7vfkj/Ybb+nW3Dk3iSPJnnD2HEOdI+vTHJ7kr1JHktyTZJ3drOR/vckz+22uzvJXPf4/G7upYn3X6Q/dyf59SSfS/InSf5u1/7KPLN40IZuoZUHk3w4yVeTnN8dYl2S38poIZpPJjmn6+MccFOSz3dt703ypSRfSPK+Fn83GjZDQUO2DfgA8KPA3wF+ntF0H78C/MsFtn9+9/prgfcucswXdce5GPg3wHdqNBvpfYzmkVnKqey/vqouBt4OvGeB19/DaH6nlwK/D2wZe+1C4Pqq+hHgL4F/WFW3MZoO481V9WLgHODngB+pqh8F/vUE/dEaYyhoyB6rqi9W1VHgIeBTNboe+kVg6wLb315VR6vqS8DzFjnmp6vqqao6DDwJ7O3aFzvmSu5/bGbbBxbZ9hWMZoOlqj4B/O+x1x6rqs8vsf+3gf8L3JDk9cB3lqhHa5ChoCH767HHR8eeH2W07sCJtl9s3dpJjnmEZ/7bOfsUa1po3+8usu2J1todf98F96+qI4zOYH6P0Wpcn1iiHq1BhoK0fH8G/Fj3+A2n8X3/GHgjQJKfZjQ76lKeYrRm97EFmM6rqn2MLlG9uEmVGjRDQVq+9wG/lORe4PylNl5Bvwb8dJIHgUsZTbP81BL77AE+lOTzjMLhziRfAD4DvKNdqRoqb0mVBiLJWcB3q+pIkpczWpLzxVMuSzNmqWucklaPLcCtSc4AngaunnI9mkGeKUinUZLrGa0tPe4DVfXb06hHOp6hIEnqOdAsSeoZCpKknqEgSeoZCpKk3v8D3qMFXhgLoh0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x_train['minimum_nights'], bins=25, log_scale=(False, True));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yea, that instance was a strong outlier, and the host was being ridiculously greedy. That's a clever way to get out a multi-year lease. Notice that we are using log-scale. Clearly, a lot of our mass is from units less than 365 days. To get a better sense of that subset, let's re-plot only units with minumum_nights < 365 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_train['minimum_nights'] > 800), np.sum(x_train['minimum_nights'] > 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset = x_train['minimum_nights']<365\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(x_train['minimum_nights'][subset], 30, log=True)\n",
    "plt.xlabel('minimum_nights')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that doesn't look too bad, as most units require < 30 nights. It's surprising that some hosts list an unreasonable requirement for the minimum number of nights. There is a risk that any host that lists such an unreasonable value might also have other incorrect information. Personally, I think anything beyond 30 days could be suspicious. If we were to exclude any unit that requires more than 30 days, how many instances would we be ignoring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.loc[x_train['minimum_nights']>30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_train['minimum_nights']>30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we'd be throwing away 436 out of our ~30k entries. That's roughly 1.5\\% of our data. While we generally want to keep and use as much data as we can, I think this is an okay amount to discard, especially considering (1) we have a decently large amount of data remaining, and (2) the entries beyond a 30-day-min could be unrealiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_subset = x_train['minimum_nights'] <= 30\n",
    "x_train = x_train.loc[good_subset]\n",
    "y_train = y_train.loc[good_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we only trimmed our training data, not our development or testing data. I am making this choice because in real scenarios, we would not know the nature of the testing data values. We pre-processed our data to ignore all data that has a price of $0, and to ignore certain columns (even if it's in the testing set), but that was fair because those columns proved to be obvious, bogus element of the dataset. However, it would be unfair to inspect the values of the training set and then to further trim the development and testing set accordingly, conditioned on certain data values.\n",
    "\n",
    "The remaining columns of our training data all have reasonable summary statistics. None of the min's or max's are cause for concern, and we have no reason to assert a certain distribution of values. Since all the feature values are within reasonable ranges, and there are no missing values (NaNs) remaining, we can confidently move foward. To recap, our remaining columns are now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'name',\n",
       " 'host_id',\n",
       " 'host_name',\n",
       " 'borough',\n",
       " 'neighbourhood',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'room_type',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'calculated_host_listings_count',\n",
       " 'availability_365']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in x_train.columns] # easier to read vertically than horizontally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have a terribly large number of features. This allows us to inspect every pairwise interaction. A scatterplot is great for this, as it provides us with a high-level picture of how every pair of features correlates. If any subplot of features depicts a linear relationship (i.e., a clear, concise path with mass concentrated together), then we can assume there exists some collinearity -- that the two features overlap in what they are capturing and that they are not independent from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_matrix(x_train, figsize=(30,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  Predicting with MLE\n",
    "\n",
    "Maximum-likelihood estimation (MLE) is a very simple model which does not require _learning_ any weight/coefficient parameters. Specifically,MLE selects the parameter value ($y$) that makes the observed data most probable, so as to maximize the likelihood function. This choice of $y$ is completely independent of $x$. That is, a MLE model returns the $y$-value that was probable in the data its seen.\n",
    "\n",
    "<br>\n",
    "<div class=\"exercise\"><b>Exercise 1:</b> Using the training data, select the MLE for $y$, where $y \\in \\{0,1\\}$. Using the development to evaluate your MLE model, what is the accuracy (the % correct)?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.650301728546589"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle_y = y_train['affordable'].value_counts().idxmax()\n",
    "np.mean(y_dev['affordable'] == mle_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.650301728546589"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [SOLUTION: REMOVE]\n",
    "mle_y = y_train['affordable'].value_counts().idxmax()\n",
    "dev_accuracy = y_dev['affordable'].value_counts()[mle_y] / len(y_dev['affordable'])\n",
    "dev_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:  Predicting with Linear Regression\n",
    "\n",
    "Now, let's actually use our features to make more informed predictions. Since our model needs to use numeric values, not textual ones, let's use **ONLY** the following features for our linear model:\n",
    "\n",
    "- `borough`, using 1-hot encodings. There are 5 distinct boroughs, so represent them via 4 unique columns.\n",
    "- `latitude`\n",
    "- `longitude`\n",
    "- `room_type`, using 1-hot encodings. There are 3 distinct room_types, so represent them via 2 unique columns.\n",
    "- `minimum_nights`\n",
    "- `number_of_reviews`\n",
    "- `calculated_host_listings_count`\n",
    "- `availability_365`\n",
    "\n",
    "<br>\n",
    "<div class=\"exercise\"><b>Exercise 2:</b> Convert `x_train` to have only the columns listed above. The shape should be 28,894 x 12 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28894 entries, 451 to 44817\n",
      "Data columns (total 13 columns):\n",
      "id                                28894 non-null int64\n",
      "name                              28883 non-null object\n",
      "host_id                           28894 non-null int64\n",
      "host_name                         28882 non-null object\n",
      "borough                           28894 non-null object\n",
      "neighbourhood                     28894 non-null object\n",
      "latitude                          28894 non-null float64\n",
      "longitude                         28894 non-null float64\n",
      "room_type                         28894 non-null object\n",
      "minimum_nights                    28894 non-null int64\n",
      "number_of_reviews                 28894 non-null int64\n",
      "calculated_host_listings_count    28894 non-null int64\n",
      "availability_365                  28894 non-null int64\n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.neighbourhood.value_counts()) # will result in too many columns if OH encoded; drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28894, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encode_cols = ['borough', 'room_type']\n",
    "oh_encoder = OneHotEncoder(drop='first').fit(x_train[encode_cols])\n",
    "x_train_jash = oh_encoder.transform(x_train[encode_cols])\n",
    "x_dev_jash = oh_encoder.transform(x_dev[encode_cols])\n",
    "x_test_jash = oh_encoder.transform(x_test[encode_cols])\n",
    "print(x_train_jash.shape)\n",
    "# now we have lost the remaining columns in x_train; use column_transformer?\n",
    "# or just use pd.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28894, 12)\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['id', 'name', 'host_id', 'host_name', 'neighbourhood']\n",
    "retain_cols = ['latitude', 'longitude', 'minimum_nights', 'number_of_reviews', 'calculated_host_listings_count', 'availability_365']\n",
    "ct = ColumnTransformer(transformers=[\n",
    "    ('drop', 'drop', drop_cols),\n",
    "    ('retain', 'passthrough', retain_cols),\n",
    "    ('oh_enc', OneHotEncoder(drop='first'), encode_cols),\n",
    "]).fit(x_train)\n",
    "\n",
    "x_train_ct = ct.transform(x_train)\n",
    "x_dev_ct = ct.transform(x_dev)\n",
    "x_test_ct = ct.transform(x_test)\n",
    "print(x_train_ct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [SOLUTION: remove!!]\n",
    "x_train = pd.get_dummies(x_train, columns=['borough', 'room_type'], drop_first=True)\n",
    "x_train = x_train.drop(['id', 'name', 'host_id', 'host_name', 'neighbourhood'], axis=1)\n",
    "\n",
    "x_dev = pd.get_dummies(x_dev, columns=['borough', 'room_type'], drop_first=True)\n",
    "x_dev = x_dev.drop(['id', 'name', 'host_id', 'host_name', 'neighbourhood'], axis=1)\n",
    "\n",
    "x_test = pd.get_dummies(x_test, columns=['borough', 'room_type'], drop_first=True)\n",
    "x_test = x_test.drop(['id', 'name', 'host_id', 'host_name', 'neighbourhood'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_dev != x_dev_ct).sum().sum() # must be 0 for x_dev and x_dev_ct to match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 3:</b> For this exercise, perform multi-linear regression and evaluate it on the development set. Do not introduce any polynomial terms or any other new features. Any prediction that is >= 0.5 should be treated as being an 'affordable' prediction. Anything below 0.5 should be 'unaffordable'. What is your accuracy %? (). Is this what you expected? Is this reasonable, and if not, what do you think are the issues?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvenepal\\Anaconda3\\envs\\cs109a\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2542: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# [SOLUTION HERE]\n",
    "# training set\n",
    "x_train_padded = sm.add_constant(x_train) # to allow for beta_0\n",
    "y_train_lr = y_train['affordable'].values.reshape(-1,1)\n",
    "\n",
    "# development set\n",
    "x_dev_padded = sm.add_constant(x_dev)\n",
    "y_dev_lr = y_dev['affordable'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.371</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.371</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1422.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:31:32</td>     <th>  Log-Likelihood:    </th> <td> -12826.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 28894</td>      <th>  AIC:               </th> <td>2.568e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 28881</td>      <th>  BIC:               </th> <td>2.579e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                          <td>   96.8761</td> <td>    6.899</td> <td>   14.042</td> <td> 0.000</td> <td>   83.354</td> <td>  110.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>latitude</th>                       <td>    0.5947</td> <td>    0.067</td> <td>    8.825</td> <td> 0.000</td> <td>    0.463</td> <td>    0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>longitude</th>                      <td>    1.6313</td> <td>    0.077</td> <td>   21.062</td> <td> 0.000</td> <td>    1.480</td> <td>    1.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minimum_nights</th>                 <td>    0.0052</td> <td>    0.000</td> <td>   17.194</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_reviews</th>              <td>    0.0008</td> <td> 5.08e-05</td> <td>   14.877</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>calculated_host_listings_count</th> <td>   -0.0007</td> <td> 7.39e-05</td> <td>   -9.368</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>availability_365</th>               <td>   -0.0004</td> <td> 1.85e-05</td> <td>  -23.768</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>borough_Brooklyn</th>               <td>    0.0728</td> <td>    0.019</td> <td>    3.828</td> <td> 0.000</td> <td>    0.036</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>borough_Manhattan</th>              <td>   -0.1229</td> <td>    0.017</td> <td>   -7.107</td> <td> 0.000</td> <td>   -0.157</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>borough_Queens</th>                 <td>   -0.0038</td> <td>    0.018</td> <td>   -0.209</td> <td> 0.835</td> <td>   -0.040</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>borough_Staten Island</th>          <td>    0.4936</td> <td>    0.036</td> <td>   13.864</td> <td> 0.000</td> <td>    0.424</td> <td>    0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_type_Private room</th>         <td>    0.4636</td> <td>    0.005</td> <td>   99.360</td> <td> 0.000</td> <td>    0.454</td> <td>    0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_type_Shared room</th>          <td>    0.5049</td> <td>    0.015</td> <td>   34.059</td> <td> 0.000</td> <td>    0.476</td> <td>    0.534</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>565.926</td> <th>  Durbin-Watson:     </th> <td>   2.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 331.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.093</td>  <th>  Prob(JB):          </th> <td>1.33e-72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.510</td>  <th>  Cond. No.          </th> <td>5.73e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.73e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.371\n",
       "Model:                            OLS   Adj. R-squared:                  0.371\n",
       "Method:                 Least Squares   F-statistic:                     1422.\n",
       "Date:                Fri, 15 Jan 2021   Prob (F-statistic):               0.00\n",
       "Time:                        08:31:32   Log-Likelihood:                -12826.\n",
       "No. Observations:               28894   AIC:                         2.568e+04\n",
       "Df Residuals:                   28881   BIC:                         2.579e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================================\n",
       "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------\n",
       "const                             96.8761      6.899     14.042      0.000      83.354     110.398\n",
       "latitude                           0.5947      0.067      8.825      0.000       0.463       0.727\n",
       "longitude                          1.6313      0.077     21.062      0.000       1.480       1.783\n",
       "minimum_nights                     0.0052      0.000     17.194      0.000       0.005       0.006\n",
       "number_of_reviews                  0.0008   5.08e-05     14.877      0.000       0.001       0.001\n",
       "calculated_host_listings_count    -0.0007   7.39e-05     -9.368      0.000      -0.001      -0.001\n",
       "availability_365                  -0.0004   1.85e-05    -23.768      0.000      -0.000      -0.000\n",
       "borough_Brooklyn                   0.0728      0.019      3.828      0.000       0.036       0.110\n",
       "borough_Manhattan                 -0.1229      0.017     -7.107      0.000      -0.157      -0.089\n",
       "borough_Queens                    -0.0038      0.018     -0.209      0.835      -0.040       0.032\n",
       "borough_Staten Island              0.4936      0.036     13.864      0.000       0.424       0.563\n",
       "room_type_Private room             0.4636      0.005     99.360      0.000       0.454       0.473\n",
       "room_type_Shared room              0.5049      0.015     34.059      0.000       0.476       0.534\n",
       "==============================================================================\n",
       "Omnibus:                      565.926   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              331.005\n",
       "Skew:                          -0.093   Prob(JB):                     1.33e-72\n",
       "Kurtosis:                       2.510   Cond. No.                     5.73e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.73e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OLS(y_train_lr, x_train_padded)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2 = 0.3714\n",
      "Test R^2 = 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7751866625754321"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "y_hat_dev = results.predict(exog=x_dev_padded)\n",
    "\n",
    "# calculating and reporting the requested values, particularly the Test R^2\n",
    "print('Train R^2 = {:.4}'.format(results.rsquared))\n",
    "print('Test R^2 = {:.4}'.format(r2_score(y_dev_lr, y_hat_dev)))\n",
    "\n",
    "# i'm using numpy's round() function, instead of manually checking for values above 0.5\n",
    "accuracy_score(y_dev, np.round(y_hat_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89726159])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predict(x_dev_padded.iloc[0].values)\n",
    "# x_dev_padded.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23240ce0108>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(y_hat_dev))\n",
    "plt.plot(y_dev_lr, '|', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7769254372506904"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev_1d = y_dev_lr.flatten()\n",
    "correct_1 = (y_dev_1d == 1) & (y_hat_dev >= 0.5)\n",
    "wrong_1 = (y_dev_1d == 1) & (y_hat_dev < 0.5)\n",
    "correct_0 = (y_dev_1d == 0) & (y_hat_dev < 0.5)\n",
    "wrong_0 = (y_dev_1d == 0) & (y_hat_dev >= 0.5)\n",
    "(np.sum(correct_0) + np.sum(correct_1)) / (np.sum(correct_0) + np.sum(correct_1) + np.sum(wrong_0) + np.sum(wrong_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2369, 1050, 5227, 1131)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(correct_0), np.sum(wrong_0), np.sum(correct_1), np.sum(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 4:</b> Akin to what you did in Homework 3, regularize your model via Ridge regression and Lasso regression. Specifically, report the model's accuracy on the development set (as you did in Exercise 2); do so while varying the alpha (aka lambda) parameter to be each of these values: [.001, .01, .05, .1, .5, 1, 5, 10, 50, 100, 500]). What is your best result?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model: Ridge(alpha=100) yielded accuracy of: 0.7777436841566943\n"
     ]
    }
   ],
   "source": [
    "# [SOLUTION HERE]\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "for cur_alpha in [0.001, .01, .05, .1, .5, 1, 5, 10, 50, 100, 500]:\n",
    "\n",
    "    # fit (using Ridge Regression), predict, and score\n",
    "    fitted_ridge = Ridge(alpha=cur_alpha).fit(x_train, y_train_lr)\n",
    "    y_hat_dev = fitted_ridge.predict(x_dev).reshape(1,-1)[0]\n",
    "    \n",
    "    cur_accuracy = accuracy_score(y_dev['affordable'].to_numpy(), np.round(y_hat_dev))\n",
    "    if cur_accuracy > best_accuracy:\n",
    "        best_accuracy = cur_accuracy\n",
    "        best_model = fitted_ridge\n",
    "    \n",
    "    # fit (using Lasso Regression), predict, and score\n",
    "    fitted_lasso = Lasso(alpha=cur_alpha).fit(x_train, y_train_lr)\n",
    "    y_hat_dev = fitted_lasso.predict(x_dev).reshape(1,-1)[0]\n",
    "    cur_accuracy = accuracy_score(y_dev['affordable'].to_numpy(), np.round(y_hat_dev))\n",
    "    if cur_accuracy > best_accuracy:\n",
    "        best_accuracy = cur_accuracy\n",
    "        best_model = fitted_lasso\n",
    "    \n",
    "print(\"best_model:\", best_model, \"yielded accuracy of:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note,** we did not perform cross-validation, so perhaps our model could have performed even better, had we done so.\n",
    "**NOte also,** that regularization doesn't improve the scores much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 5:</b> Plot two histograms of the residuals from your best performing linear regression model (having trained on the training set, one plot should show the distribution of training set residuals and another plot for the distribution of development set residuals). Does this adhere to the assumptions of a linear model?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min residual: -6.374920636446429\n"
     ]
    }
   ],
   "source": [
    "# [SOLUTION HERE]\n",
    "\n",
    "# construct training residuals\n",
    "y_hat_train = best_model.predict(x_train)\n",
    "training_residuals = y_train_lr[:,0] - y_hat_train[:,0]\n",
    "\n",
    "# construct dev residuals\n",
    "y_hat_dev = best_model.predict(x_dev).reshape(1,-1)[0]\n",
    "dev_residuals = y_dev['affordable'].to_numpy() - y_hat_dev\n",
    "\n",
    "# make plot of training residuals\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "axes[0].set_title('Histogram of Training Residuals')\n",
    "axes[0].hist(training_residuals, alpha=0.8, bins=20)\n",
    "axes[0].axhline(0, c='black', lw=2)\n",
    "axes[0].set_xlabel(r'residuals')\n",
    "\n",
    "# make plot of dev residuals\n",
    "axes[1].set_title('Histogram of Development Residuals')\n",
    "axes[1].hist(dev_residuals, alpha=0.4, bins=20)\n",
    "axes[1].axhline(0, c='black', lw=2)\n",
    "axes[1].set_xlabel(r'residuals')\n",
    "plt.show()\n",
    "\n",
    "print(\"min residual:\", min(dev_residuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plots suggest that the training data is not too conducive to being modelled by a linear regression model, for the residuals seem to be bimodal -- there isn't a single normal distrubion of residual values. Also, just for fun, we plotted the errors/residuals from having evaluated on the unseen development set. Doing so would provide no information about the assumptions of linear model being appropriate for our training data (as the unseen data could be completely dissimiliar from anything we saw during training). Yet, we hope that the development set residuals would be minimal, and it's nice that the errors seem to follow a normal distrubtion -- although, there's some outliers that we perform badly on, but this can happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 4: Binary Logistic Regression\n",
    "Linear regression is usually a good baseline model, but since the outcome we're trying to predict only takes values 0 and 1 we'll want to use logistic regression instead of basic linear regression.\n",
    "\n",
    "We will use `sklearn` for now, but `statsmodels` also provides LogisticRegression, along with nifty features like confidence intervals.\n",
    "\n",
    "First, let's import the necessary classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, let's instantiate a new LogisticRegression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit our model with just 1 line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000, max_iter=2000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1000000, max_iter=2000)\n",
    "lr.fit(x_train, y_train['affordable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compare the model we have with the model CV chooses\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(max_iter=2000)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv = LogisticRegressionCV(max_iter=2000).fit(x_train, y_train['affordable'])\n",
    "lrcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04641589])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 6:</b> Using .predict(), make predictions on the development set </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [.predict()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) documentation here. **NOTE:** regularization is applied by default. Especially pay attention to the following arguments/parameters:\n",
    "\n",
    "- **C** penalty, which we discussed in class. Experiment with varying values from 0 to 100 million! \n",
    "- **max_iterations**: experiment with values from 5 to 5000. Do you expect more iterations to always perform better? Why or why not?\n",
    "- **penalty**: for designating L1 (Lasso) or L2 (Ridge) loss; default is L2\n",
    "- **solver**: especially for the multi-class setting\n",
    "\n",
    "After fitting the model, you can print the ``.coef_`` value to see its coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our initial logistic regression model yielded accuracy score of: 0.7737547304899254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best logistic regression model: LogisticRegression(C=10000000, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=5000, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) yielded an accuracy score: 0.7737547304899254\n",
      "its learned coefficients: 12\n",
      "the coefficients align with our features: (9777, 12)\n"
     ]
    }
   ],
   "source": [
    "y_hat_dev = lr.predict(x_dev)\n",
    "initial_score = accuracy_score(y_dev['affordable'].to_numpy(), y_hat_dev)\n",
    "print(\"our initial logistic regression model yielded accuracy score of:\", initial_score)\n",
    "\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "\n",
    "# experiment with different values\n",
    "c_vals = [1, 10, 100, 1000, 10000, 100000, 1000000, 10000000]\n",
    "num_iters = [5, 10, 100, 1000, 5000]\n",
    "for c_val in c_vals:\n",
    "    for num_iter in num_iters:\n",
    "        lr = LogisticRegression(C=c_val, solver='liblinear', max_iter=num_iter)\n",
    "        lr.fit(x_train, y_train['affordable'])\n",
    "        y_hat_dev = lr.predict(x_dev)\n",
    "        cur_accuracy = accuracy_score(y_dev['affordable'].to_numpy(), y_hat_dev)\n",
    "\n",
    "        if cur_accuracy > best_accuracy:\n",
    "            best_accuracy = cur_accuracy\n",
    "            best_model = lr\n",
    "\n",
    "print(\"best logistic regression model:\", lr, \"yielded an accuracy score:\", best_accuracy)\n",
    "print(\"its learned coefficients:\", len(best_model.coef_[0]))\n",
    "print(\"the coefficients align with our features:\", x_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results here should show that for this dataset, logistic regression offered effectively identical performance as linear regression. There are two main takeaways from this:\n",
    "- logistic regression should not be viewed as being _superior_ to linear regression; it should be viewed as a solution to a different type of problem -- **classification** (predicting categorical outputs), not **regression** (predicting continuous-valued outputs).\n",
    "- In our situation, our two categories/classes (affordable or not) had an ordinal nature. That is, the continuum of prices directly aligned with the structure of our two classes. Alternatively, you could imagine other scenarios where our two categories are nominal and thus un-rankable (e.g., predicting cancer or not, or predicting which NYC borough an AirBnB is in based on its property features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 5 (The Real Challenge): Multiclass Classification\n",
    "Before we move on, let's consider a more common use case of logistic regression: predicting not just a binary variable, but what level a categorical variable will take. Instead of breaking the price variable into two classes (affordable being true or false), we may care for more fine-level granularity.\n",
    "\n",
    "For this exercise, go back to the original `df` dataframe and construct 5 classes of pricing:\n",
    "\n",
    "- budget: < 80\n",
    "- affordable: 80 < x < 120\n",
    "- average: 120 < x < 180\n",
    "- expensive: 180 < x < 240\n",
    "- very expensive: 240 < x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `cut` function obviously stores a lot of extra information for us. It's a very useful tool for discretizing an existing variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 8:</b> After making the new categories, perform the same predictions as above. Compare your results. What improvements could we make? (not just w/ the parameters, but with possibly expanding and using other features from our original dataset!)</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates multi-class labels for training\n",
    "x_train_multiclass = x_train.copy()\n",
    "x_train_multiclass['price_level'] = pd.cut(df_train['price'],[0,80,120,180,240,float('inf')], labels=[0,1,2,3,4])\n",
    "y_train_multiclass = pd.DataFrame(data=x_train_multiclass['price_level'], columns=[\"price_level\"])\n",
    "x_train_multiclass = x_train_multiclass.drop(['price_level'], axis=1)\n",
    "\n",
    "# creats multi-class labels for dev\n",
    "x_dev_multiclass = x_dev.copy()\n",
    "x_dev_multiclass['price_level'] = pd.cut(df_dev['price'],[0,80,120,180,240,float('inf')], labels=[0,1,2,3,4])\n",
    "y_dev_multiclass = pd.DataFrame(data=x_dev_multiclass['price_level'], columns=[\"price_level\"])\n",
    "x_dev_multiclass = x_dev_multiclass.drop(['price_level'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n",
      "0.5167229211414545\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = -1\n",
    "best_model = None\n",
    "\n",
    "# experiment with different values\n",
    "c_vals = [1, 10, 100, 1000, 10000]\n",
    "num_iters = [10, 100, 1000, 5000]\n",
    "for c_val in c_vals:\n",
    "    for num_iter in num_iters:\n",
    "        lr = LogisticRegression(solver=\"lbfgs\", max_iter=10000)\n",
    "        lr.fit(x_train_multiclass, y_train_multiclass['price_level'])\n",
    "        y_hat_dev = lr.predict(x_dev_multiclass)\n",
    "        cur_accuracy = accuracy_score(y_dev_multiclass['price_level'].to_numpy(), y_hat_dev)\n",
    "        print(cur_accuracy)\n",
    "        if cur_accuracy > best_accuracy:\n",
    "            best_accuracy = cur_accuracy\n",
    "            best_model = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best logistic regression model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) yielded an accuracy score: 0.5048583410043981\n",
      "its learned coefficients: 12\n",
      "the coefficients align with our features: (9777, 12)\n",
      "feature: latitude ; coef: 7.312415440262378\n",
      "feature: longitude ; coef: 4.059059803768657\n",
      "feature: minimum_nights ; coef: 0.044388062697350704\n",
      "feature: number_of_reviews ; coef: 0.0013794514234422481\n",
      "feature: calculated_host_listings_count ; coef: -0.0034845157546768537\n",
      "feature: availability_365 ; coef: -0.0021468646692259148\n",
      "feature: borough_Brooklyn ; coef: 0.19507151988381405\n",
      "feature: borough_Manhattan ; coef: -1.7898799616161736\n",
      "feature: borough_Queens ; coef: 0.06310066394457561\n",
      "feature: borough_Staten Island ; coef: 2.4381414950649947\n",
      "feature: room_type_Private room ; coef: 3.4513468035217554\n",
      "feature: room_type_Shared room ; coef: 4.686077440118879\n"
     ]
    }
   ],
   "source": [
    "print(\"best logistic regression model:\", lr, \"yielded an accuracy score:\", best_accuracy)\n",
    "print(\"its learned coefficients:\", len(best_model.coef_[0]))\n",
    "print(\"the coefficients align with our features:\", x_dev.shape)\n",
    "for i in range(len(x_dev.columns)):\n",
    "    print(\"feature:\", x_dev.columns[i], \"; coef:\", best_model.coef_[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite having 5 distinct price categories now, our performance isn't too bad! To increase performance further, we could first use cross-validation. Then, we could look at our original data and try to better use its features. For example, perhaps it would be useful to expand out our 'neighbourhood' feature into one-hot encodings? I imagine the fine-level, granular information of 'neighbourhood' correlates well with price. The only concern and question to ask ourselves is how much data do we have for each neighbourhood? (We'd aim to have plenty of representative data). Related, the longitude and latitude features provide fine-level information, but perhaps it's hard for the model to use it since the range is so small. If we were to scale the lat and long values to be between 0 and 1, it might allow for the model to better distinguish between the nuanced values.\n",
    "\n",
    "For this exercise, we uniformly care about each price level and prediction thereof. However, in some scenarios, our classification accuracy for some categories is much more important than others (e.g., predicting cancer or not). That is, our false negatives (misses) are way more serious and potentially deadly. For situations like this, it is better to error on the side of caution and allow for false positives (aka false alarms) moreso than false negatives (misses). To handle this, one could weight each class, and specify such during training/ fitting our model. As we learned in class, we can plot the performance as we vary the prediction threshold, while paying attention to how that affects the number of false negatives and false positives."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
